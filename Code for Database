# CNA 330 Group Project fuel prices throughout the years. How the pandemic has affected gas prices#
# Collaborated with Eric, Dillion, Igor, Vlado, Mohammad,
# Help from Justin Ellis & Zac Rubin #
# 12/9/2020 #
# This script pulls from the eia website and stores fuel prices into a database. It takes the information and compiles into a xcel sheet.
# CNA 330 Group Project


import pandas as pd
from sqlalchemy import create_engine
import mysql.connector
import json
import urllib.request
import time



# database config
db_host = 'localhost'
db_username = 'root'
db_password = ''
db_port = '3306'
db_name = 'sqlgroupproject'

"""db_host = 'url'
db_username = 'admin'
db_password = 'root1root'
db_port = '3306'
db_name = 'sqlgroupproject' """

# The url for the source web page
html_source_url = "https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=EMD_EPD2D_PTE_R50_DPG&f=W"

#Code for table
tables = pandas.read_excel ('https://www.eia.gov/dnav/pet/hist_xls/EMD_EPD2D_PTE_R50_DPGw.xls', sheet_name='Data 1',
                            header = 2, index_col='Date')

#code for graphing panda instert
writer = pd.ExcelWriter('farm_data.xlsx', engine='xlsxwriter')
df.to_excel(writer, sheet_name='Sheet1')

workbook = writer.book
worksheet = writer.sheets['Sheet1']

chart = workbook.add_chart({'type': 'column'})


# Connect to database
# You may need to edit the connect function based on your local settings.
def connect_to_sql():
    conn = mysql.connector.connect(user='root', password='',
                                  host='127.0.0.1',
                                  database='sqlgroupproject')
    return conn

# Create the table structure
def create_tables(cursor, table):
    ## Add your code here. Starter code below
    cursor.execute('''CREATE TABLE IF NOT EXISTS jobs (id INT PRIMARY KEY auto_increment,
                            Type varchar(10), Title varchar(100), Description TEXT, Job_id varchar(36),
                            Created_at DATE, Company varchar(100), location varchar(50),
                            How_to_apply varchar(1000)); ''')
    return

# Query the database.
# You should not need to edit anything in this function
def query_sql(cursor, query):
    cursor.execute(query)
    return cursor

# Add a new job
def add_new_job(cursor, jobdetails):
    ## Add your code here
    type = jobdetails['type']
    title = jobdetails['title']
    description = jobdetails ['description']
    job_id = jobdetails['id']
    created_at = time.strptime(jobdetails['created_at'], "%a %b %d %H:%M:%S %Z %Y")
    company = jobdetails['company']
    location = jobdetails['location']
    how_to_apply = jobdetails['how_to_apply']
    query = cursor.execute("INSERT INTO jobs(Type, Title,Description, Job_id,Created_at, Company, Location, How_to_apply" ") "
               "VALUES(%s,%s,%s,%s,%s,%s,%s,%s)", (type, title, description, job_id, created_at, company, location, how_to_apply))
    return query_sql(cursor, query)

# Check if new job
def check_if_job_exists(cursor, jobdetails):
    ## Add your code here

    job_id = jobdetails['id']
    query = "SELECT * FROM jobs WHERE Job_id = \"%s\"" % job_id
    return query_sql(cursor, query)

def delete_job(cursor, jobdetails):
    ## Add your code here

    job_id = jobdetails['id']
    query = "DELETE FROM jobs WHERE Job_id = \"%s\"" % job_id
    return query_sql(cursor, query)

# Grab new jobs from a website
def fetch_new_jobs(arg_dict):
    # Code from https://github.com/RTCedu/CNA336/blob/master/Spring2018/Sql.py
    query = "https://jobs.github.com/positions.json?search=SQL&location=Remote"
    jsonpage = 0
    try:
        contents = urllib.request.urlopen(query)
        response = contents.read()
        jsonpage = json.loads(response)
    except:
        pass
    return jsonpage
# Main area of the code.
def jobhunt(arg_dict, cursor):
    # Fetch jobs from website
    jobpage = fetch_new_jobs(arg_dict)

    ## Add your code here to parse the job page
    add_or_delete_job(jobpage, cursor)
def add_or_delete_job(jobpage, cursor):

    # Add your code here to parse the job page
    for jobdetails in jobpage:
        # Add in your code here to check if the player already exists in the DB
        check_if_job_exists(cursor, jobdetails)
        is_job_found = len(cursor.fetchall()) > 0
        ## Add in your code here to notify the user of a new posting
        if is_job_found:
            print("job is found: " + jobdetails["title"] + " from " + jobdetails["company"])
        else:
            print("New job is found: " + jobdetails["title"] + " from " + jobdetails["company"])
            add_new_job(cursor, jobdetails)

# Setup portion of the program. Take arguments and set up the script
def main():
    # Connect to SQL and get cursor
    conn = connect_to_sql()
    cursor = conn.cursor()
    create_tables(cursor, "table")

    # Load text file and store arguments into dictionary
    arg_dict = 0
    while (1):
        jobhunt(arg_dict, cursor)
        conn.commit()
        time.sleep(3600)


if __name__ == '__main__':
    main()
 
